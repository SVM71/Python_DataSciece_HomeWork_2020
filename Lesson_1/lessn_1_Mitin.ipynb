{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Тема “Вычисления с помощью Numpy”"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Задание 1\n",
    "Импортируйте библиотеку Numpy и дайте ей псевдоним np.\n",
    "Создайте массив Numpy под названием a размером 5x2, \n",
    "то есть состоящий из 5 строк и 2 столбцов. \n",
    "Первый столбец должен содержать числа 1, 2, 3, 3, 1, а \n",
    "второй - числа 6, 8, 11, 10, 7. \n",
    "Будем считать, что каждый столбец - это признак, а строка - наблюдение. \n",
    "Затем найдите среднее значение по каждому признаку, используя метод mean массива Numpy. \n",
    "Результат запишите в массив mean_a, в нем должно быть 2 элемента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  6]\n",
      " [ 2  8]\n",
      " [ 3 11]\n",
      " [ 3 10]\n",
      " [ 1  7]]\n",
      "==========\n",
      "[2.  8.4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array( [ \n",
    "    [1, 2, 3, 3, 1], \n",
    "    [6, 8, 11, 10, 7] \n",
    "] ).T\n",
    "mean_a = np.mean(a, axis = 0 )\n",
    "print(a)\n",
    "print(10*'=')\n",
    "print(mean_a)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Задание 2\n",
    "Вычислите массив a_centered, отняв от значений массива “а” средние значения соответствующих признаков, \n",
    "содержащиеся в массиве mean_a. Вычисление должно производиться в одно действие. \n",
    "Получившийся массив должен иметь размер 5x2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  -2.4]\n",
      " [ 0.  -0.4]\n",
      " [ 1.   2.6]\n",
      " [ 1.   1.6]\n",
      " [-1.  -1.4]]\n"
     ]
    }
   ],
   "source": [
    "a_centered = (a - mean_a)\n",
    "print(a_centered)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Задание 3\n",
    "Найдите скалярное произведение столбцов массива a_centered. \n",
    "В результате должна получиться величина a_centered_sp. \n",
    "Затем поделите a_centered_sp на N-1, где N - число наблюдений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "half = int(a_centered.size/2)\n",
    "a_centered_sp = (a_centered[:half, 0] @ a_centered[:half, 1])/(half-1)\n",
    "print(a_centered_sp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Задание 4**\n",
    "Число, которое мы получили в конце задания 3 является ковариацией двух признаков, содержащихся \n",
    "в массиве “а”. В задании 4 мы делили сумму произведений центрированных признаков на N-1, а не \n",
    "на N, поэтому полученная нами величина является несмещенной оценкой ковариации.\n",
    "Подробнее узнать о ковариации можно здесь:\n",
    "https://studopedia.ru/9_153900_viborochnaya-kovariatsiya-i-viborochnaya-dispersiya.html\n",
    "В этом задании проверьте получившееся число, вычислив ковариацию еще одним способом - с помощью функции np.cov. \n",
    "В качестве аргумента m функция np.cov должна принимать транспонированный массив “a”. \n",
    "В получившейся ковариационной матрице (массив Numpy размером 2x2) искомое значение ковариации будет \n",
    "равно элементу в строке с индексом 0 и столбце с индексом 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 == 2.0 True\n"
     ]
    }
   ],
   "source": [
    "print(np.cov(a.T)[0, 1], f'== {a_centered_sp}', np.cov(a.T)[0, 1] == a_centered_sp )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Тема “Работа с данными в Pandas”"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Задание 1\n",
    "Импортируйте библиотеку Pandas и дайте ей псевдоним pd. Создайте датафрейм authors со\n",
    "столбцами author_id и author_name, в которых соответственно содержатся данные: [1, 2, 3] и\n",
    "['Тургенев', 'Чехов', 'Островский'].\n",
    "Затем создайте датафрейм book cо столбцами author_id, book_title и price, в которых соответственно\n",
    "содержатся данные:\n",
    "[1, 1, 1, 2, 2, 3, 3],\n",
    "['Отцы и дети', 'Рудин', 'Дворянское гнездо', 'Толстый и тонкий', 'Дама с собачкой', 'Гроза', 'Таланты и\n",
    "поклонники'],\n",
    "[450, 300, 350, 500, 450, 370, 290]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "authors_dic = {\n",
    "    \"author_id\": [1, 2, 3],\n",
    "    \"author_name\": ['Тургенев', 'Чехов', 'Островский']\n",
    "}\n",
    "\n",
    "authors = pd.DataFrame(authors_dic)\n",
    "\n",
    "books_dic = {\n",
    "    \"author_id\": [1, 1, 1, 2, 2, 3, 3],\n",
    "    \"book_title\": ['Отцы и дети', 'Рудин', 'Дворянское гнездо', \\\n",
    "                   'Толстый и тонкий', 'Дама с собачкой', 'Гроза', \\\n",
    "                   'Таланты и поклонники'],\n",
    "    \"price\": [450, 300, 350, 500, 450, 370, 290]\n",
    "}\n",
    "books = pd.DataFrame(books_dic)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Задание 2\n",
    "Получите датафрейм authors_price, соединив датафреймы authors и books по полю author_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   author_id author_name            book_title  price\n",
      "0          1    Тургенев           Отцы и дети    450\n",
      "1          1    Тургенев                 Рудин    300\n",
      "2          1    Тургенев     Дворянское гнездо    350\n",
      "3          2       Чехов      Толстый и тонкий    500\n",
      "4          2       Чехов       Дама с собачкой    450\n",
      "5          3  Островский                 Гроза    370\n",
      "6          3  Островский  Таланты и поклонники    290\n"
     ]
    }
   ],
   "source": [
    "authors_price = pd.merge(authors, books, on='author_id', how='left')\n",
    "print(authors_price)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Задание 3\n",
    "Создайте датафрейм top5, в котором содержатся строки из authors_price \n",
    "с пятью самыми дорогими книгами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   author_id author_name         book_title  price\n",
      "3          2       Чехов   Толстый и тонкий    500\n",
      "0          1    Тургенев        Отцы и дети    450\n",
      "4          2       Чехов    Дама с собачкой    450\n",
      "5          3  Островский              Гроза    370\n",
      "2          1    Тургенев  Дворянское гнездо    350\n"
     ]
    }
   ],
   "source": [
    "authors_price = authors_price.sort_values(by=\"price\", ascending=False)\n",
    "print(authors_price.head(5))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Задание 4\n",
    "Создайте датафрейм authors_stat на основе информации из authors_price. В датафрейме authors_stat должны быть четыре столбца:\n",
    "author_name, min_price, max_price и mean_price,\n",
    "в которых должны содержаться соответственно имя автора,минимальная, максимальная и средняя\n",
    "цена на книги этого автора.\n",
    "https://habr.com/ru/post/501214/\n",
    "\n",
    "В Методичке ошибка!!! Такой вариант: \n",
    "    groupby.agg({\"price\": \"max\", \"total\": \"count\"})\n",
    "НЕ РАБОТАЕТ!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             min_price  max_price  mean_price\n",
      "author_name                                  \n",
      "Островский         290        370  330.000000\n",
      "Тургенев           300        450  366.666667\n",
      "Чехов              450        500  475.000000\n",
      "             author_id                            price                       \n",
      "            <lambda_0> <lambda_1> <lambda_2> <lambda_0> <lambda_1>  <lambda_2>\n",
      "author_name                                                                   \n",
      "Островский           3          3          3        290        370  330.000000\n",
      "Тургенев             1          1          1        300        450  366.666667\n",
      "Чехов                2          2          2        450        500  475.000000\n"
     ]
    }
   ],
   "source": [
    "grpby = authors_price.groupby(\"author_name\").agg(\n",
    "    min_price = pd.NamedAgg(column = 'price', aggfunc = 'min'),\n",
    "    max_price = pd.NamedAgg(column = 'price', aggfunc = 'max'),\n",
    "    mean_price = pd.NamedAgg(column = 'price', aggfunc = 'mean')\n",
    ")\n",
    "print ( grpby )\n",
    "\n",
    "grpby_1 = authors_price.groupby(\"author_name\").agg(\n",
    "    [lambda x: x.min(), \n",
    "     lambda x: x.max(), \n",
    "     lambda x: x.mean() \n",
    "    ]\n",
    ")\n",
    "print ( grpby_1 )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Задание 5**\n",
    "Создайте новый столбец в датафрейме authors_price под названием cover, в нем будут располагаться данные о том, какая обложка у данной книги - твердая или мягкая. В этот столбец поместите данные из следующего списка:\n",
    "['твердая', 'мягкая', 'мягкая', 'твердая', 'твердая', 'мягкая', 'мягкая'].\n",
    "\n",
    "Просмотрите документацию по функции pd.pivot_table с помощью вопросительного знака.Для каждого автора посчитайте суммарную стоимость книг в твердой и мягкой обложке. Используйте для этого функцию pd.pivot_table. При этом столбцы должны называться \"твердая\" и \"мягкая\", а индексами должны быть фамилии авторов. Пропущенные значения стоимостей заполните нулями, при необходимости загрузите библиотеку Numpy. Назовите полученный датасет book_info и сохраните его в формат pickle под названием \"book_info.pkl\". Затем загрузите из этого файла датафрейм и назовите его book_info2. Удостоверьтесь, что датафреймы book_info и book_info2 идентичны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "   author_id author_name            book_title  price    cover\n",
      "3          2       Чехов      Толстый и тонкий    500  твердая\n",
      "0          1    Тургенев           Отцы и дети    450   мягкая\n",
      "4          2       Чехов       Дама с собачкой    450   мягкая\n",
      "5          3  Островский                 Гроза    370  твердая\n",
      "2          1    Тургенев     Дворянское гнездо    350  твердая\n",
      "1          1    Тургенев                 Рудин    300   мягкая\n",
      "6          3  Островский  Таланты и поклонники    290   мягкая\n",
      "========================================\n",
      "            author_id          price        \n",
      "cover          мягкая твердая мягкая твердая\n",
      "author_name                                 \n",
      "Островский          3       3    290     370\n",
      "Тургенев            2       1    750     350\n",
      "Чехов               2       2    450     500\n",
      "========================================\n",
      "Is read from pickle file datasetequals to original dataframe: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "authors_price[\"cover\"] = \\\n",
    "['твердая', 'мягкая', 'мягкая', 'твердая', 'твердая', 'мягкая', 'мягкая']\n",
    "\n",
    "print( '=' * 40 )\n",
    "print(authors_price)\n",
    "book_info = pd.pivot_table( authors_price, index=\"author_name\", aggfunc=np.sum, \\\n",
    "                       columns=['cover'], fill_value=0,)\n",
    "print( '=' * 40 )\n",
    "print ( book_info )\n",
    "\n",
    "book_info.to_pickle(\"book_info.pkl\")\n",
    "book_info_1 = pd.read_pickle(\"book_info.pkl\")\n",
    "print( '=' * 40 )\n",
    "print( f'Is read from pickle file dataset\\\n",
    "equals to original dataframe: {book_info_1.equals(book_info)}' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pivot_table in module pandas.core.reshape.pivot:\n",
      "\n",
      "pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False) -> 'DataFrame'\n",
      "    Create a spreadsheet-style pivot table as a DataFrame.\n",
      "    \n",
      "    The levels in the pivot table will be stored in MultiIndex objects\n",
      "    (hierarchical indexes) on the index and columns of the result DataFrame.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data : DataFrame\n",
      "    values : column to aggregate, optional\n",
      "    index : column, Grouper, array, or list of the previous\n",
      "        If an array is passed, it must be the same length as the data. The\n",
      "        list can contain any of the other types (except list).\n",
      "        Keys to group by on the pivot table index.  If an array is passed,\n",
      "        it is being used as the same manner as column values.\n",
      "    columns : column, Grouper, array, or list of the previous\n",
      "        If an array is passed, it must be the same length as the data. The\n",
      "        list can contain any of the other types (except list).\n",
      "        Keys to group by on the pivot table column.  If an array is passed,\n",
      "        it is being used as the same manner as column values.\n",
      "    aggfunc : function, list of functions, dict, default numpy.mean\n",
      "        If list of functions passed, the resulting pivot table will have\n",
      "        hierarchical columns whose top level are the function names\n",
      "        (inferred from the function objects themselves)\n",
      "        If dict is passed, the key is column to aggregate and value\n",
      "        is function or list of functions.\n",
      "    fill_value : scalar, default None\n",
      "        Value to replace missing values with.\n",
      "    margins : bool, default False\n",
      "        Add all row / columns (e.g. for subtotal / grand totals).\n",
      "    dropna : bool, default True\n",
      "        Do not include columns whose entries are all NaN.\n",
      "    margins_name : str, default 'All'\n",
      "        Name of the row / column that will contain the totals\n",
      "        when margins is True.\n",
      "    observed : bool, default False\n",
      "        This only applies if any of the groupers are Categoricals.\n",
      "        If True: only show observed values for categorical groupers.\n",
      "        If False: show all values for categorical groupers.\n",
      "    \n",
      "        .. versionchanged:: 0.25.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        An Excel style pivot table.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.pivot : Pivot without aggregation that can handle\n",
      "        non-numeric data.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
      "    ...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
      "    ...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
      "    ...                          \"one\", \"one\", \"two\", \"two\"],\n",
      "    ...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
      "    ...                          \"small\", \"large\", \"small\", \"small\",\n",
      "    ...                          \"large\"],\n",
      "    ...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
      "    ...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
      "    >>> df\n",
      "         A    B      C  D  E\n",
      "    0  foo  one  small  1  2\n",
      "    1  foo  one  large  2  4\n",
      "    2  foo  one  large  2  5\n",
      "    3  foo  two  small  3  5\n",
      "    4  foo  two  small  3  6\n",
      "    5  bar  one  large  4  6\n",
      "    6  bar  one  small  5  8\n",
      "    7  bar  two  small  6  9\n",
      "    8  bar  two  large  7  9\n",
      "    \n",
      "    This first example aggregates values by taking the sum.\n",
      "    \n",
      "    >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      "    ...                     columns=['C'], aggfunc=np.sum)\n",
      "    >>> table\n",
      "    C        large  small\n",
      "    A   B\n",
      "    bar one    4.0    5.0\n",
      "        two    7.0    6.0\n",
      "    foo one    4.0    1.0\n",
      "        two    NaN    6.0\n",
      "    \n",
      "    We can also fill missing values using the `fill_value` parameter.\n",
      "    \n",
      "    >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      "    ...                     columns=['C'], aggfunc=np.sum, fill_value=0)\n",
      "    >>> table\n",
      "    C        large  small\n",
      "    A   B\n",
      "    bar one      4      5\n",
      "        two      7      6\n",
      "    foo one      4      1\n",
      "        two      0      6\n",
      "    \n",
      "    The next example aggregates by taking the mean across multiple columns.\n",
      "    \n",
      "    >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      "    ...                     aggfunc={'D': np.mean,\n",
      "    ...                              'E': np.mean})\n",
      "    >>> table\n",
      "                    D         E\n",
      "    A   C\n",
      "    bar large  5.500000  7.500000\n",
      "        small  5.500000  8.500000\n",
      "    foo large  2.000000  4.500000\n",
      "        small  2.333333  4.333333\n",
      "    \n",
      "    We can also calculate multiple types of aggregations for any given\n",
      "    value column.\n",
      "    \n",
      "    >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      "    ...                     aggfunc={'D': np.mean,\n",
      "    ...                              'E': [min, max, np.mean]})\n",
      "    >>> table\n",
      "                    D    E\n",
      "                mean  max      mean  min\n",
      "    A   C\n",
      "    bar large  5.500000  9.0  7.500000  6.0\n",
      "        small  5.500000  9.0  8.500000  8.0\n",
      "    foo large  2.000000  5.0  4.500000  4.0\n",
      "        small  2.333333  6.0  4.333333  2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
